#!/usr/bin/env python3
"""
–¢–µ—Å—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞ —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –≤—Å–µ—Ö –ø–∞—Ä—Å–µ—Ä–æ–≤
"""

import os
import sys
import logging
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent))

from app.pipeline.universal_parser import UniversalParser
from app.pipeline.detector import detect_text_layer
from app.pipeline.extractor import extract_text_and_tables
from app.db.database import init_database

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s: %(message)s'
)

def test_universal_parser():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –Ω–∞ –≤—Å–µ—Ö —Ñ–∞–π–ª–∞—Ö"""
    print("\nüîß –¢–ï–°–¢ –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–û–ì–û –ü–ê–†–°–ï–†–ê")
    print("=" * 60)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    init_database()
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä
    parser = UniversalParser()
    
    # –ü–∞–ø–∫–∞ —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏
    inbox_dir = Path("inbox")
    
    if not inbox_dir.exists():
        print("‚ùå –ü–∞–ø–∫–∞ inbox –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ PDF —Ñ–∞–π–ª–æ–≤
    pdf_files = list(inbox_dir.glob("*.pdf"))
    
    if not pdf_files:
        print("‚ùå PDF —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–∞–ø–∫–µ inbox")
        return
    
    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(pdf_files)} PDF —Ñ–∞–π–ª–æ–≤")
    
    total_processed = 0
    total_items_found = 0
    
    for pdf_file in pdf_files:
        print(f"\nüìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {pdf_file.name}")
        print("-" * 50)
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å–ª–æ—è
            has_text, char_count, info = detect_text_layer(str(pdf_file))
            
            if has_text:
                print(f"‚úÖ –¢–µ–∫—Å—Ç–æ–≤—ã–π —Å–ª–æ–π –Ω–∞–π–¥–µ–Ω ({char_count} —Å–∏–º–≤–æ–ª–æ–≤)")
            else:
                print(f"‚ö†Ô∏è –¢–µ–∫—Å—Ç–æ–≤—ã–π —Å–ª–æ–π –Ω–µ –Ω–∞–π–¥–µ–Ω")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏ —Ç–∞–±–ª–∏—Ü—ã
            text, tables, metadata = extract_text_and_tables(str(pdf_file))
            print(f"üìä –ò–∑–≤–ª–µ—á–µ–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(tables)}")
            
            # –ü–∞—Ä—Å–∏–º –¥–æ–∫—É–º–µ–Ω—Ç
            results = parser.parse_document(text, tables)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            best_parser = results.get('best_parser')
            best_items = results.get('best_items', [])
            document_type = results.get('document_type')
            
            print(f"üéØ –õ—É—á—à–∏–π –ø–∞—Ä—Å–µ—Ä: {best_parser}")
            print(f"üìã –¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞: {document_type}")
            print(f"üì¶ –ù–∞–π–¥–µ–Ω–æ –ø–æ–∑–∏—Ü–∏–π: {len(best_items)}")
            
            if best_items:
                total_cost = sum(item.get('total', 0) for item in best_items)
                avg_confidence = sum(item.get('confidence', 0) for item in best_items) / len(best_items)
                print(f"üí∞ –û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: {total_cost:,.2f} —Ä—É–±.")
                print(f"üéØ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence:.1%}")
                
                print(f"\nüìã –ù–ê–ô–î–ï–ù–ù–´–ï –ü–û–ó–ò–¶–ò–ò:")
                for i, item in enumerate(best_items, 1):
                    name = item.get('name', 'N/A')
                    qty = item.get('qty', 'N/A')
                    unit = item.get('unit', '')
                    price = item.get('price', 'N/A')
                    total = item.get('total', 'N/A')
                    article = item.get('article', '')
                    
                    print(f"  {i}. {name}")
                    if article:
                        print(f"     –ê—Ä—Ç–∏–∫—É–ª: {article}")
                    print(f"     –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {qty} {unit}")
                    print(f"     –¶–µ–Ω–∞: {price:,.2f} —Ä—É–±.")
                    print(f"     –°—É–º–º–∞: {total:,.2f} —Ä—É–±.")
                    print()
                
                total_items_found += len(best_items)
            else:
                print(f"‚ùå –ü–æ–∑–∏—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö –ø–∞—Ä—Å–µ—Ä–æ–≤
                print(f"\nüîç –†–ï–ó–£–õ–¨–¢–ê–¢–´ –í–°–ï–• –ü–ê–†–°–ï–†–û–í:")
                parsers = ['commercial_parser', 'invoice_parser', 'competitive_parser', 
                          'universal_parser', 'supplier_profile_parser', 'table_extractor', 'precise_table_parser']
                
                for parser_name in parsers:
                    parser_result = results.get(parser_name, {})
                    if 'error' in parser_result:
                        print(f"  {parser_name}: ‚ùå {parser_result['error']}")
                    else:
                        count = parser_result.get('count', 0)
                        total_cost = parser_result.get('total_cost', 0)
                        avg_confidence = parser_result.get('avg_confidence', 0)
                        print(f"  {parser_name}: {count} –ø–æ–∑–∏—Ü–∏–π, {total_cost:,.2f} —Ä—É–±., {avg_confidence:.1%}")
            
            total_processed += 1
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {e}")
            continue
    
    print(f"\nüéâ –¢–ï–°–¢ –ó–ê–í–ï–†–®–ï–ù!")
    print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {total_processed}")
    print(f"üì¶ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–∑–∏—Ü–∏–π: {total_items_found}")

if __name__ == "__main__":
    test_universal_parser()
